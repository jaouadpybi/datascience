{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "071c10ea",
   "metadata": {},
   "source": [
    "##  PREDICTIVE MODELING\n",
    "### LOGISTIC REGRESSION FOR PREDICTIVE MODELING\n",
    "### Jaouad Safouani "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9830142",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd \n",
    "# display all columns in the dataframe.\n",
    "import numpy as np\n",
    "#format numbers\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc(\"font\", size=14)\n",
    "%matplotlib inline\n",
    "import seaborn as sns \n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "import statsmodels.api as sm\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# importing math library\n",
    "import math\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score,confusion_matrix, accuracy_score \n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17f4d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('churn_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6209abf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc79ab52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e39e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76583e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(list(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631532f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314984c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_to_be_dropped_list = ['CaseOrder', 'Customer_id', 'Interaction', 'UID','TimeZone','Job','County'\n",
    "                          ,'State','City','Zip', 'Lat','Lng','Population', 'Area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91788845",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping columns\n",
    "df.drop(columns = var_to_be_dropped_list , inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c5d517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename last 8 survey columns to the appropriate description per the data dictionary\n",
    "df.rename(columns = {'Item1':'TimelyResponse', \n",
    "                     'Item2':'Fixes', \n",
    "                     'Item3':'Replacements', \n",
    "                     'Item4':'Reliability', \n",
    "                     'Item5':'Options', \n",
    "                     'Item6':'Respectfulness', \n",
    "                     'Item7':'Courteous', \n",
    "                     'Item8':'Listening'}, \n",
    "          inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5924ecb",
   "metadata": {},
   "source": [
    "#### Count of Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1714082",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x= \"Churn\", data= df,\n",
    "    order = df[\"Churn\"].value_counts().index)\n",
    "for p, label in zip(ax.patches, df[\"Churn\"].value_counts()):\n",
    "    ax.annotate(label, (p.get_x()+0.375, p.get_height()+0.15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bfd732",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean of all variables by churn\n",
    "df.groupby('Churn').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dafcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent_variables = [col for col in df.columns if col!='Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c596f290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = df[Independent_variables]\n",
    "# X = df['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97437a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Independent_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57eec310",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fb0a68",
   "metadata": {},
   "source": [
    "### Distribution of categorical and numerical vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecb5c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary with columns and their datatype. \n",
    "dict_col_type = dict()\n",
    "for col in list(df.columns):\n",
    "    dict_col_type[col] = df[col].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c9c980",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_col_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b30ed0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric_variable= dict()\n",
    "df_object_variable =dict()\n",
    "for i, v in dict_col_type.items():\n",
    "    if (dict_col_type[i]=='int64' or dict_col_type[i]=='float64'):\n",
    "        df_numeric_variable[i]= v\n",
    "    else:\n",
    "        df_object_variable[i] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec0115b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_object_variable\n",
    "df_numeric_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d7ed29",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_obj  = sorted(list(df_object_variable.keys()))\n",
    "var_obj_cnt = int(len(var_obj)/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6917cd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_obj_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130583b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#distribution of all categorical variables in df\n",
    "\n",
    "fig, axes = plt.subplots(nrows = var_obj_cnt ,ncols = 3,\n",
    "figsize = (20,25))\n",
    "for i, item in enumerate(var_obj):\n",
    "    if i < 6:\n",
    "        ax = df[item].value_counts().plot(\n",
    "        kind = 'bar',ax=axes[i,0],\n",
    "        rot = 15 )\n",
    "        \n",
    "    elif i >=6 and i < 12:\n",
    "        ax = df[item].value_counts().plot(\n",
    "        kind = 'bar',ax=axes[i-6,1],\n",
    "        rot = 15, color ='orange')\n",
    "        \n",
    "    elif i >= 12 and i<18:\n",
    "        ax = df[item].value_counts().plot(\n",
    "        kind = 'bar',ax=axes[i-12,2],\n",
    "        rot = 15)\n",
    "    for p, label in zip(ax.patches, df[item].value_counts()):\n",
    "        ax.annotate(label, (p.get_x() +0.15, p.get_height()+.4))\n",
    "        \n",
    "    ax.set_title(item, fontsize =14)\n",
    "# plt.annotate(df[item].value_counts())\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.89, \n",
    "                    top=0.89, \n",
    "                    wspace=0.2, \n",
    "                    hspace=0.65)\n",
    "\n",
    "\n",
    "plt.savefig(\"CountOfCategoricalVariables.png\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed14fca0",
   "metadata": {},
   "source": [
    "#### Describe df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bac551f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd27642f",
   "metadata": {},
   "source": [
    "By calling df.describe(), we notice that on average a customer is 53 years old has 2 children with 10 seconds of outage per week and income of 39806.926771 and emailed customer service 12 times.\n",
    "We also notice that 75% of the customers has 3 children and are 71 years old and have about 12 second of outage per week with and income of 39806.926771 and emailed customer service 14.\n",
    "With standard deviation for children 2.1472 and Age 20.69 and 2.97 second of outage per week and income of 28199.916702 and email 3.02.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a047a00",
   "metadata": {},
   "source": [
    "### Numerical Variables distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87777d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_num_list = sorted(list(df_numeric_variable.keys()))\n",
    "len(var_num_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ae8d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_num_list = sorted(list(df_numeric_variable.keys()))\n",
    "sns.set(font_scale=1.23)\n",
    "fig, axes = plt.subplots(nrows = int(len(var_num_list)/3) ,ncols = 3,\n",
    "figsize = (20,20))\n",
    "for i, item in enumerate(var_num_list):\n",
    "    if i < 6:\n",
    "        sns.boxplot(x= item, data = df,showmeans=True,ax=axes[i,0])\n",
    "        \n",
    "    elif i >=6 and i < 12:\n",
    "        sns.boxplot(x= item, data = df,showmeans=True,ax=axes[i-6,1],color ='orange')\n",
    "        \n",
    "    elif i >= 12 and i<18:\n",
    "         sns.boxplot(x= item, data = df,showmeans=True,ax=axes[i-12,2],color ='#feefc0')\n",
    "\n",
    "        \n",
    "#     ax.set_title(item, fontsize =14)\n",
    "    \n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=1, \n",
    "                    wspace=0.2, \n",
    "                    hspace=0.3)\n",
    "\n",
    "plt.savefig(\"IdentifyingOutliersNumericalVar.png\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023ef438",
   "metadata": {},
   "source": [
    "After Investigation the outlies they deemed to be acceptable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59ee039",
   "metadata": {},
   "source": [
    "## Bivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3122c0",
   "metadata": {},
   "source": [
    "### Categorical by Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5969e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bivariate_exclude_chrun = [col for col in var_obj if col !='Churn']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2851581c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows = var_obj_cnt ,ncols = 3,\n",
    "figsize = (22,25))\n",
    "\n",
    "for i, item in enumerate(bivariate_exclude_chrun):\n",
    "    cat_churn = df.groupby([item,'Churn']).size().unstack()\n",
    "    # Transpose the columns into rows than devide each row value by the total of the each column \n",
    "    # to calculte of percetage of column\n",
    "    if i < 6:\n",
    "        ax = (cat_churn.T*100.0 / cat_churn.T.sum()).T.plot(kind='bar',\n",
    "                                                                      ax=axes[i,0],\n",
    "                                                                      stacked = True,\n",
    "                                                                      rot =15,\n",
    "                                                            figsize = (25,40))\n",
    "\n",
    "        ax.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "\n",
    "        for p in ax.patches:\n",
    "            width, height = p.get_width(), p.get_height()\n",
    "            x, y = p.get_xy() \n",
    "            ax.text(x+width/2, \n",
    "                    y+height/4, \n",
    "                    '{:.1f}%'.format(height), \n",
    "                    horizontalalignment='center', \n",
    "                    verticalalignment='center')\n",
    "        ax.autoscale(enable=False, axis='both', tight=False)\n",
    "        \n",
    "    elif i >=6 and i < 12:\n",
    "        ax = (cat_churn.T*100.0 / cat_churn.T.sum()).T.plot(kind='bar',\n",
    "                                                                      ax=axes[i-6,1],\n",
    "                                                                      stacked = True,\n",
    "                                                                      rot =15,\n",
    "                                                            figsize = (25,40))\n",
    "\n",
    "        ax.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "\n",
    "        for p in ax.patches:\n",
    "            width, height = p.get_width(), p.get_height()\n",
    "            x, y = p.get_xy() \n",
    "            ax.text(x+width/2, \n",
    "                    y+height/4, \n",
    "                    '{:.1f}%'.format(height), \n",
    "                    horizontalalignment='center', \n",
    "                    verticalalignment='center')\n",
    "        ax.autoscale(enable=False, axis='both', tight=False)\n",
    "        \n",
    "\n",
    "    elif i >= 12 and i<17:\n",
    "        ax = (cat_churn.T*100.0 / cat_churn.T.sum()).T.plot(kind='bar',\n",
    "                                                                      ax=axes[i-12,2],\n",
    "                                                                      stacked = True,\n",
    "                                                                      rot =15,\n",
    "                                                            figsize = (25,40))\n",
    "\n",
    "        ax.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "\n",
    "        for p in ax.patches:\n",
    "            width, height = p.get_width(), p.get_height()\n",
    "            x, y = p.get_xy() \n",
    "            ax.text(x+width/2, \n",
    "                    y+height/4, \n",
    "                    '{:.1f}%'.format(height), \n",
    "                    horizontalalignment='center', \n",
    "                    verticalalignment='center')\n",
    "        ax.autoscale(enable=False, axis='both', tight=False)\n",
    "\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.89, \n",
    "                    top=1, \n",
    "                    wspace=0.2, \n",
    "                    hspace=0.4)\n",
    "\n",
    "\n",
    "plt.savefig(\"BivariateAnalysis_CategoricalByChurn.png\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7808fc0d",
   "metadata": {},
   "source": [
    " * We conclude from the bivariate analysis that the month to month contract has more churn at 37.3% compared to the other contract types\n",
    " * DSL has more churn at 32.2% compared to other internet services.\n",
    " * people that stream movies tend to churn compared to people who do not.\n",
    " * the rest of categorical variables tend to have similar stats by churn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ff860e",
   "metadata": {},
   "source": [
    "### Distribution of Numerical Variables by Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4122694",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_var_numcnt = math.ceil(len(var_num_list)/3)\n",
    "sns.set(font_scale=1.23)\n",
    "\n",
    "fig, axes = plt.subplots(nrows = df_var_numcnt ,ncols = 3,\n",
    "figsize = (22,25))\n",
    "for i, item in enumerate(var_num_list):\n",
    "    if i < 6:\n",
    "        sns.histplot(x= item, data = df,ax=axes[i,0], hue ='Churn',multiple=\"stack\")\n",
    "        \n",
    "    elif i >=6 and i < 12:\n",
    "        sns.histplot(x= item, data = df,ax=axes[i-6,1], hue ='Churn',multiple=\"stack\")\n",
    "        \n",
    "    elif i >= 12 and i<18:\n",
    "         sns.histplot(x= item, data =df,ax=axes[i-12,2], hue ='Churn',multiple=\"stack\")\n",
    "            \n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.2, \n",
    "                    hspace=0.3)\n",
    "\n",
    "plt.savefig(\"BivariateHistogram_NumericalByChurn.png\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adc5167",
   "metadata": {},
   "source": [
    "We conlude from the the distirubution of the numerical variables bu churn the following:\n",
    "* Clients that churned  are client that send most emails and have larger outage sec perweek even they had Timely Response and Options and customer was curteous.\n",
    "* Churned customer has less Tenure and had fewer average data usage per year.\n",
    "* Churned Customers are from all ages, there is a uniform distributiion regradless of if a customer churned or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f2bf99",
   "metadata": {},
   "source": [
    "### variance_inflation_factor on Numerical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a674fd6",
   "metadata": {},
   "source": [
    "Let's check for multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b57b61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variance_inflation_factor\n",
    "df_new_model = df[var_num_list]\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = var_num_list\n",
    "vif['VIF'] = [variance_inflation_factor(df_new_model.values, i) for i in range(df_new_model.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b4b568",
   "metadata": {},
   "source": [
    "by Using VIF we notice that\n",
    "* Bandwidth_GB_Year\t312.45\n",
    "* Tenure\t246.96\n",
    "seemed to be correlated let's verif them in the correlation matrix and drop one of them\n",
    "that goes for \n",
    "* TimelyResponse\t27.23\n",
    "* Fixes\t24.03\n",
    "they seem to be correlated \n",
    "that goes for \n",
    "* MonthlyCharge\t21.88\n",
    "* Replacements\t19.82\n",
    "they seem to be correlated "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd8f7c9",
   "metadata": {},
   "source": [
    "### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21499e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f, ax = plt.subplots(figsize=(25, 25))\n",
    "df_chrun_corr= df[var_num_list]\n",
    "sns.heatmap(df_chrun_corr.corr(), annot=True,cmap=\"YlGnBu\",square=True, vmax=1)\n",
    "plt.title(\"Independent variables Correlation Matrix\", fontsize = 24)\n",
    "plt.savefig(\"IndependentVarialbesCorrMatrix.png\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1cdc6b",
   "metadata": {},
   "source": [
    "The correlation matrix confirm that:\n",
    "    \n",
    "Bandwidth_GB_Year is highly correlated with Tenure: 0.99 we will need to drop the Tenure as it makes more sense to use Bandwidth_GB_Year as in input to predict customer that are going to churn per research question\n",
    "\n",
    "TimelyResponse is correlated with both Fixes: 0.66 and with Replacements at 0.58, also there is a correlation between Replacement and Fixes. We will drop both Fixes and Replacements.\n",
    "MonthlyCharge and Replacements are not correlated. \n",
    "Conclusion:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a64ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_corre_var_to_be_droped = ['Tenure', 'Replacements','Fixes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9534ab40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = multi_corre_var_to_be_droped, inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08513e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify that the columns were dropped\n",
    "print(sorted(list(df.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b759976",
   "metadata": {},
   "source": [
    "## Re-expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2436a211",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the columns with string values and a lis the numerical columns.\n",
    "list_object_col  =[]\n",
    "list_numeric_col =[]\n",
    "for col , _type in dict_col_type.items():\n",
    "    if 'object' in str(_type):\n",
    "        list_object_col.append(col)\n",
    "    else:\n",
    "        list_numeric_col.append(col)\n",
    "#Assign unique values for each object variable and store data in a dictionary        \n",
    "dict_col_withdistinct_values=dict()\n",
    "for col in list_object_col:\n",
    "    dict_col_withdistinct_values[col]= df[col].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe74239",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,values in dict_col_withdistinct_values.items():\n",
    "    print(key,\" : \", values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a2956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify columns with Yes/ NO \n",
    "# We will use ordinal Encoding for variables with Yes No \n",
    "# and One hot Encoding for the other categorical non ordinal columns.\n",
    "List_var_Yes_No=[]\n",
    "List_var_Other=[]\n",
    "for key,values in dict_col_withdistinct_values.items():\n",
    "    if 'No' in values and 'Yes' in values:\n",
    "        List_var_Yes_No.append(key)\n",
    "    else:\n",
    "        List_var_Other.append(key)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2eb2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "List_var_Other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa37dfa",
   "metadata": {},
   "source": [
    "### Ordinal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19d492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(List_var_Yes_No))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b006002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the map function to replace Yes and No with 1 and 0\n",
    "# Ordinal Encoding\n",
    "def Yes_No_dict_map(x):\n",
    "    ''' Ordinal Encoding '''\n",
    "    return x.map({'Yes':1, 'No':0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afc8887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the Yes and No with 1 and 0 in binary variables.\n",
    "# Applying Ordinal encoding to Re express Yes No to 1 and 0 respectevely.\n",
    "df[List_var_Yes_No]=df[List_var_Yes_No].apply(Yes_No_dict_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48761bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verifying that the encoding was successful\n",
    "df[List_var_Yes_No].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ac8a10",
   "metadata": {},
   "source": [
    "### One-Hot Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6bad9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(List_var_Other))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35d1cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_var_Other = dict()\n",
    "for key,values in dict_col_withdistinct_values.items():\n",
    "    if key in List_var_Other:\n",
    "        dict_var_Other[key] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a03a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7d52b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using One hot encoding to prepare the data multi leaner regresssion model.\n",
    "# Notice we are dropping the first column in the dummy data frame to avoid the dummy-variable trap, \n",
    "# resulting from the One hot encoding.\n",
    "\n",
    "for col in dict_var_Other.keys():\n",
    "    df_ = pd.get_dummies(df[col], drop_first = True).astype('int64')\n",
    "    df = pd.concat([df, df_], axis = 1)\n",
    "    df.drop(columns = col, inplace = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d01301",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropped None as it is an outliers.\n",
    "df.drop(columns=['None'], inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd0a3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2a77bb",
   "metadata": {},
   "source": [
    "## Bivariate Analysis of the distribution of the Re-expressed variables by Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e7e7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_columns = sorted(list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fa3c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_columnscnt =math.ceil(len(df_columns)/3)\n",
    "df_columnscnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93eda45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create distribution plot of all df.\n",
    "sns.set(font_scale=1.23)\n",
    "fig, axes = plt.subplots(nrows = df_columnscnt ,ncols = 3,\n",
    "figsize = (22,35))\n",
    "for i, item in enumerate(df_columns):\n",
    "    if i < 14:\n",
    "        sns.histplot(x= item, data = df,ax=axes[i,0],hue ='Churn')\n",
    "        \n",
    "    elif i >=14 and i < 28:\n",
    "        sns.histplot(x= item, data = df,ax=axes[i-14,1],hue ='Churn')\n",
    "        \n",
    "    elif i >= 28and i<40:\n",
    "         sns.histplot(x= item, data = df,ax=axes[i-28,2],hue ='Churn')\n",
    "            \n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.89, \n",
    "                    top=1, \n",
    "                    wspace=0.2, \n",
    "                    hspace=0.4)\n",
    "\n",
    "plt.savefig(\"DistibutionOfRe_expression_By_Churn.png\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a872beeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_predictors = sorted([col for col in df.columns if col !='Churn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b28f882",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a6d0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_df_columns= list_predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc1d5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_df_columns.append('Churn')\n",
    "print(ordered_df_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5ea032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy to csv of the oreoared data.\n",
    "df.to_csv(\"lr_prepared_churn_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb219610",
   "metadata": {},
   "source": [
    "## Logistic Regression Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f8b4b9",
   "metadata": {},
   "source": [
    "Lets's set apha = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71ef734",
   "metadata": {},
   "source": [
    "Let's split the predicted variable from the predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26083e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Churn']\n",
    "y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72a0b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(columns=['Churn'], inplace =True)\n",
    "# X=df\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfb8232",
   "metadata": {},
   "source": [
    "### Split the data into training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a2be36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spliting the data into training and testing subsets randomly.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,stratify=y,test_size = 0.3, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc79b0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print shape of the 4 data sets, training and testing\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd34e53",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635661d5",
   "metadata": {},
   "source": [
    "Let's scale the features using StandardScaler, the scaler will change the values to vlaues between -1 and 1. This step is necessary for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d3844c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d85b44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_copy = pd.DataFrame(scaler.fit_transform(X_train))\n",
    "X_train_copy.columns = X_train.columns.values\n",
    "X_train_copy.index = X_train.index.values\n",
    "X_train = X_train_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d582664",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_copy = pd.DataFrame(scaler.transform(X_test))\n",
    "X_test_copy.columns = X_test.columns.values\n",
    "X_test_copy.index = X_test.index.values\n",
    "X_test = X_test_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dfcf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b63a062",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c868c3",
   "metadata": {},
   "source": [
    "### Logistic Regression - initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9abe89",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_model = sm.Logit(endog=y_train, exog=X_train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b42b62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(initial_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cdbeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get odds ratio\n",
    "np.exp(initial_model.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcb7972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predicted values for the test dataset [0, 1]\n",
    "pred = initial_model.predict(exog=X_test)\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66953495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# round(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f55adec",
   "metadata": {},
   "outputs": [],
   "source": [
    "intial_model_confusion_matrix = confusion_matrix(y_true=y_test, y_pred=list(round(pred)))\n",
    "intial_model_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f8b3e5",
   "metadata": {},
   "source": [
    "* 1486 True Negative (TN)\n",
    "* 785 True Positive (TP)\n",
    "* 10 False Negative (FN)\n",
    "* 719 False Positive (FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd6d29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1score = f1_score(y_true=y_test, y_pred=list(round(pred)))\n",
    "precisionscore = precision_score(y_true=y_test, y_pred=list(round(pred)))\n",
    "recallscore = recall_score(y_true=y_test, y_pred=list(round(pred)))\n",
    "accuracyscore = accuracy_score(y_true=y_test, y_pred=list(round(pred)))\n",
    "\n",
    "Initial_Model_stats = pd.DataFrame([['Initial Logistic Regression', \n",
    "accuracyscore, precisionscore, recallscore, f1score]], columns = ['Model', \n",
    "'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "Initial_Model_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35e1716",
   "metadata": {},
   "source": [
    "### Equation: Initial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149bbd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating the MLR Equation for initial Model\n",
    "LR_equation = []\n",
    "for var, coef in initial_model.params.items():\n",
    "    LR_equation.append( '( ' + str(round(coef, 3)) + ' * ' + var  + ' )' )\n",
    "' + '.join(LR_equation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7e6084",
   "metadata": {},
   "source": [
    "### Explanation of the coefficient of the Lr model equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd13fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_exp=[]\n",
    "\n",
    "for var, coef in initial_model.params.items():\n",
    "    if var != 'constant':\n",
    "        if coef >0:\n",
    "            variable_exp.append( 'For each unit of '  + var +  ' variable, the odds of response of 1 will increase by ' + str(round(coef, 3)) + ' units')\n",
    "        else:\n",
    "            variable_exp.append( 'For each unit of '  + var +  ' variable, the odds of response of 0 increase by ' + str(round(abs(coef), 3)) + ' units')\n",
    "            \n",
    "variable_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1d30b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56e30f53",
   "metadata": {},
   "source": [
    "## Reduced_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9588f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduced_model.pvalues\n",
    "# pvalue_reduced = pd.DataFrame(initial_model.pvalues, columns=['pvalue'])\n",
    "# feature_with_significant_pvalue = sorted(pvalue_reduced[pvalue_reduced['pvalue'] <0.05].index)\n",
    "# feature_with_significant_pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7030da2d",
   "metadata": {},
   "source": [
    "lets run the variance_inflation_factor to identify correlated independent variables and rid of one of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2a34b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variance_inflation_factor\n",
    "reduced_model = X_train\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train.columns\n",
    "vif['VIF'] = [variance_inflation_factor(reduced_model.values, i) for i in range(reduced_model.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f1a393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67103f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(40, 40))\n",
    "X_train_chrun_corr= X_train\n",
    "sns.heatmap(X_train_chrun_corr.corr(), annot=True,cmap=\"YlGnBu\",square=True, vmax=1)\n",
    "plt.title(\"Independent variables Correlation Matrix\", fontsize = 24)\n",
    "plt.savefig(\"ReducedCorrMatrix.png\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b89516",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(columns=['StreamingMovies'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453e2192",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.drop(columns=['StreamingMovies'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c667b1",
   "metadata": {},
   "source": [
    "### Let's remove the insignificant independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0253060",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_model_pvalues = pd.DataFrame(initial_model.pvalues, columns=['pvalues'])\n",
    "new_predictors = sorted(list(reduced_model_pvalues[reduced_model_pvalues['pvalues']<0.05].index))\n",
    "new_predictors = [col for col in new_predictors if col !='StreamingMovies' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c58cabe",
   "metadata": {},
   "source": [
    "### New training and testing X datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ced2263",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_X_test = X_test[new_predictors]\n",
    "reduced_X_train = X_train[new_predictors]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cb71e8",
   "metadata": {},
   "source": [
    "### Reduced Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff71893",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_final_model = sm.Logit(endog=y_train, exog= reduced_X_train).fit()\n",
    "print(reduced_final_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d05b78",
   "metadata": {},
   "source": [
    "#### get the predicted values for the test dataset [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8cd8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_final = reduced_final_model.predict(exog=reduced_X_test)\n",
    "# pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf52c7f8",
   "metadata": {},
   "source": [
    "####  Reduced_model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddcabb8",
   "metadata": {},
   "source": [
    "##### reduced_model_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a5da6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_model_confusion_matrix = confusion_matrix(y_true=y_test, y_pred=list(round(pred_final)))\n",
    "reduced_model_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0a793b",
   "metadata": {},
   "source": [
    "##### Model Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e127df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1score = f1_score(y_true=y_test, y_pred=list(round(pred_final)))\n",
    "precisionscore = precision_score(y_true=y_test, y_pred=list(round(pred_final)))\n",
    "recallscore = recall_score(y_true=y_test, y_pred=list(round(pred_final)))\n",
    "accuracyscore = accuracy_score(y_true=y_test, y_pred=list(round(pred_final)))\n",
    "\n",
    "reduced_Model_stats = pd.DataFrame([['Reduced Logistic Regression', \n",
    "accuracyscore, precisionscore, recallscore, f1score]], columns = ['Model', \n",
    "'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "reduced_Model_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a38b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating the MLR Equation for reduced model\n",
    "LR_equation = []\n",
    "for var, coef in reduced_final_model.params.items():\n",
    "    LR_equation.append( '( ' + str(round(coef, 3)) + ' * ' + var  + ' )' )\n",
    "' + '.join(LR_equation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2355c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_exp=[]\n",
    "\n",
    "for var, coef in reduced_final_model.params.items():\n",
    "    if var != 'constant':\n",
    "        if coef >0:\n",
    "            variable_exp.append( 'For each unit of '  + var +  ' variable, the odds of response of 1 will increase by ' + str(round(coef, 3)) + ' units')\n",
    "        else:\n",
    "            variable_exp.append( 'For each unit of '  + var +  ' variable, the odds of response of 0 increase by ' + str(round(abs(coef), 3)) + ' units')\n",
    "            \n",
    "variable_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb92dd6",
   "metadata": {},
   "source": [
    "### Model stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f57ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(intial_model_confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351b5164",
   "metadata": {},
   "source": [
    "Initial Logistic Regression\n",
    "* 1486 True Negative (TN)\n",
    "* 785 True Positive (TP)\n",
    "* 10 False Negative (FN)\n",
    "* 719 False Positive (FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9a95a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reduced_model_confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80199705",
   "metadata": {},
   "source": [
    "Reduced Logistic Regression\n",
    "* 1479 True Negative (TN)\n",
    "* 782 True Positive (TP)\n",
    "* 13 False Negative (FN)\n",
    "* 726 False Positive (FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47b8363",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_Model_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03523d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stats = Initial_Model_stats.append(reduced_Model_stats, ignore_index=True)\n",
    "model_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ba2627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d85506b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
